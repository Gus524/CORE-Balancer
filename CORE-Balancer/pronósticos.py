# -*- coding: utf-8 -*-
"""Pronósticos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H4kQaRqGAfRKW1g8wKd6z80uwZg5JWAi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import warnings
import os # <--- AÑADIDO: Para manejar rutas y directorios
from sklearn.preprocessing import MinMaxScaler
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense, Input
# from tensorflow.keras.callbacks import EarlyStopping
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.models import load_model # <--- AÑADIDO: Para cargar modelos guardados
import tensorflow as tf # Importar tensorflow completo es común
# Ignorar warnings comunes (opcional)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", message="Do not pass an `input_shape`")

# --- Parámetros de Datos ---
ARCHIVO_CSV = '/content/drive/MyDrive/Colab Notebooks/CORE-Balancer/Salidas/supply_demand.csv' # Nombre del archivo CSV
TRIMESTRE_INICIO = 'Q3 95'
TRIMESTRE_FIN = 'Q4 03'
DEMAND_COLUMN = 'EffectiveDemand'
PRODUCT_ID_COLUMN = 'PID'
QUARTER_COLUMN = 'Quarter'

# --- Parámetros de Conversión Semanal ---
RATIO_DEMANDA_SEMANAL_STD = [0.055, 0.055, 0.055, 0.055, 0.055, 0.055, 0.055, 0.055, 0.06, 0.1, 0.1, 0.15, 0.15]
RATIO_DEMANDA_SEMANAL_Q4_96 = [0.055, 0.055, 0.055, 0.055, 0.055, 0.055, 0.038, 0.036, 0.036, 0.06, 0.1, 0.1, 0.15, 0.15]

# --- Parámetros del Modelo LSTM ---
SEQUENCE_LENGTH = 13
TEST_SPLIT_RATIO = 0.2
LSTM_UNITS_L1 = 64
LSTM_UNITS_L2 = 64
DENSE_UNITS = 32
EPOCHS = 100
BATCH_SIZE = 32
PATIENCE_EARLY_STOP = 10

# --- Parámetros de Pronóstico Futuro ---
N_FUTURE_WEEKS = 13

# --- Directorio para Guardar Modelos ---
SAVE_DIR = 'trained_models' # <--- AÑADIDO: Nombre del directorio para guardar

def quarter_to_date(q_str):
    """Convierte string 'Quarter' (ej: 'Q2 95') a objeto Timestamp (inicio de trimestre)."""
    if not isinstance(q_str, str):
        return pd.NaT
    match = re.match(r'Q(\d)\s+(\d{2})', q_str)
    if match:
        q, yy = map(int, match.groups())
        year = 1900 + yy if yy >= 90 else 2000 + yy # Ajuste para años 90s vs 2000s
        month = (q - 1) * 3 + 1 # Q1->1, Q2->4, Q3->7, Q4->10
        return pd.Timestamp(f'{year}-{month:02d}-01')
    return pd.NaT # Retorna Not a Time si el formato no coincide

# ------------------------------------------------------------------------------

def load_and_filter_data(filename, quarter_col, start_quarter_str, end_quarter_str):
    """
    Carga datos del CSV, convierte trimestres a fechas y filtra por rango.
    (Sin cambios respecto a la versión anterior)
    """
    print(f"Cargando datos desde: {filename}")
    try:
        df_raw = pd.read_csv(filename)
        print("Archivo CSV cargado exitosamente.")
    except FileNotFoundError:
        print(f"Error: El archivo '{filename}' no se encontró.")
        return None
    except Exception as e:
        print(f"Error al cargar el archivo CSV: {e}")
        return None

    if quarter_col not in df_raw.columns:
        print(f"Error: La columna '{quarter_col}' no se encuentra en el archivo.")
        return None

    df_raw['Date'] = df_raw[quarter_col].apply(quarter_to_date)
    original_rows = len(df_raw)
    df_raw.dropna(subset=['Date'], inplace=True)
    if len(df_raw) < original_rows:
         print(f"Se eliminaron {original_rows - len(df_raw)} filas por formato de '{quarter_col}' inválido.")
    if df_raw.empty:
        print("Error: No quedaron datos después de procesar la columna de trimestre.")
        return None

    start_date = quarter_to_date(start_quarter_str)
    end_date = quarter_to_date(end_quarter_str)

    if pd.isna(start_date) or pd.isna(end_date):
        print(f"Error: Formato de trimestre inválido en inicio o fin.")
        return None
    if start_date > end_date:
        print(f"Error: Trimestre inicial posterior al final.")
        return None

    print(f"Filtrando datos desde {start_quarter_str} hasta {end_quarter_str}...")
    df_filtered = df_raw[(df_raw['Date'] >= start_date) & (df_raw['Date'] <= end_date)].copy()

    if df_filtered.empty:
        print("Advertencia: No se encontraron datos en el rango especificado.")
    else:
        print(f"Filtrado completado: {len(df_filtered)} registros.")
    return df_filtered

# ------------------------------------------------------------------------------

def convertir_trimestral_a_semanal(df_q, ratio_std, ratio_q496):
    """
    Convierte DataFrame trimestral (productos como columnas) a demanda semanal.
    (Sin cambios respecto a la versión anterior)
    """
    df_weekly_list = []
    if df_q.empty: return None
    print("\nIniciando conversión trimestral a semanal...")
    product_cols = df_q.columns.tolist()

    for idx, row in df_q.iterrows():
        quarter = idx.quarter
        year = idx.year
        num_weeks, ratios = (14, ratio_q496) if (year == 1996 and quarter == 4) else (13, ratio_std)
        weekly_dates = pd.date_range(start=idx, periods=num_weeks, freq='W-MON')
        for i in range(num_weeks):
            week_data = {'Date': weekly_dates[i]}
            for product_col in product_cols:
                q_val = row[product_col]
                week_data[product_col] = (q_val * ratios[i]) if pd.notna(q_val) and isinstance(q_val, (int, float)) else 0
            df_weekly_list.append(week_data)

    if not df_weekly_list: return None
    df_weekly = pd.DataFrame(df_weekly_list)
    try:
        if df_weekly['Date'].duplicated().any():
            print("¡Advertencia! Fechas semanales duplicadas detectadas. Agrupando...")
            df_weekly = df_weekly.groupby('Date').sum()
        else:
            df_weekly.set_index('Date', inplace=True)
        df_weekly.sort_index(inplace=True)
        print("Conversión a semanal completada.")
    except Exception as e:
        print(f"Error en agrupación/indexación semanal: {e}")
        return None
    if df_weekly.empty: return None
    return df_weekly

# ------------------------------------------------------------------------------

def create_sequences(data, sequence_length):
    """Crea secuencias de entrada (X) y salida (y) para LSTM."""
    # (Sin cambios respecto a la versión anterior)
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i:(i + sequence_length)])
        y.append(data[i + sequence_length])
    return np.array(X).astype(np.float32), np.array(y).astype(np.float32)

df_filtrado_raw = load_and_filter_data(ARCHIVO_CSV, QUARTER_COLUMN, TRIMESTRE_INICIO, TRIMESTRE_FIN)
df_weekly = None
if df_filtrado_raw is not None and not df_filtrado_raw.empty:
    print("\n--- Iniciando Preprocesamiento ---")
    if DEMAND_COLUMN not in df_filtrado_raw.columns or PRODUCT_ID_COLUMN not in df_filtrado_raw.columns:
         print(f"Error: Faltan columnas '{DEMAND_COLUMN}' o '{PRODUCT_ID_COLUMN}'.")
         df_quarterly_pivot = None
    else:
        if not pd.api.types.is_numeric_dtype(df_filtrado_raw[DEMAND_COLUMN]):
            print(f"Convirtiendo '{DEMAND_COLUMN}' a numérico...")
            df_filtrado_raw[DEMAND_COLUMN] = pd.to_numeric(df_filtrado_raw[DEMAND_COLUMN], errors='coerce')
            rows_before = len(df_filtrado_raw)
            df_filtrado_raw.dropna(subset=[DEMAND_COLUMN], inplace=True)
            if len(df_filtrado_raw) < rows_before: print(f"Se eliminaron {rows_before - len(df_filtrado_raw)} filas.")

        print("Pivotando tabla...")
        try:
            df_quarterly_pivot = df_filtrado_raw.pivot_table(index='Date', columns=PRODUCT_ID_COLUMN, values=DEMAND_COLUMN)
            df_quarterly_pivot.fillna(0, inplace=True)
            df_quarterly_pivot.sort_index(inplace=True)
            print("Datos trimestrales pivotados:")
            print(df_quarterly_pivot.head())
        except Exception as e:
            print(f"Error al pivotar: {e}")
            df_quarterly_pivot = None

    if df_quarterly_pivot is not None and not df_quarterly_pivot.empty:
        df_weekly = convertir_trimestral_a_semanal(df_quarterly_pivot, RATIO_DEMANDA_SEMANAL_STD, RATIO_DEMANDA_SEMANAL_Q4_96)
        if df_weekly is not None and not df_weekly.empty:
            print("\n--- Resultado Conversión Semanal ---")
            print(df_weekly.head())
            df_weekly.info()
        else: df_weekly = None
    else: df_weekly = None
else: df_weekly = None

data_processed = {}
scalers = {}
available_products = []
if df_weekly is not None and not df_weekly.empty:
    print(f"\n--- Iniciando Preparación Datos LSTM (SeqLen={SEQUENCE_LENGTH}, TestSplit={TEST_SPLIT_RATIO:.0%}) ---")
    product_columns = df_weekly.columns.tolist()
    for product in product_columns:
        print(f"\nProcesando PID: {product}")
        product_data = df_weekly[[product]].values.astype(np.float32)
        if len(product_data) < SEQUENCE_LENGTH + 2:
            print(f"  Advertencia: Datos insuficientes ({len(product_data)}). Saltando.")
            continue

        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(product_data.reshape(-1, 1))
        scalers[product] = scaler
        X, y = create_sequences(scaled_data, SEQUENCE_LENGTH)

        if X.shape[0] < 2:
            print(f"  Advertencia: Insuficientes secuencias ({X.shape[0]}). Saltando.")
            continue

        X = X.reshape(X.shape[0], X.shape[1], 1)
        split_index = int(X.shape[0] * (1 - TEST_SPLIT_RATIO))
        split_index = max(1, min(split_index, X.shape[0] - 1))
        X_train, X_test = X[:split_index], X[split_index:]
        y_train, y_test = y[:split_index], y[split_index:]

        if X_train.shape[0] == 0 or X_test.shape[0] == 0:
             print(f"  Advertencia: Train/Test vacío post-split. Saltando.")
             continue

        data_processed[product] = {
            'X_train': X_train, 'y_train': y_train, 'X_test': X_test, 'y_test': y_test,
            'scaler': scaler, 'last_sequence': scaled_data[-SEQUENCE_LENGTH:].reshape(1, SEQUENCE_LENGTH, 1)
        }
        available_products.append(product)
        print(f"  Datos listos: X_train={X_train.shape}, X_test={X_test.shape}")
    print(f"\nProductos disponibles para modelado: {available_products}")
else:
    print("\nNo hay datos semanales para preparar LSTM.")
if not available_products:
    print("\nError Crítico: No hay productos para modelar.")

def build_lstm_model(input_shape, lstm_units_l1, lstm_units_l2, dense_units):
    """Construye la arquitectura del modelo LSTM."""
    model = tf.keras.models.Sequential(name=f"LSTM_Model_{input_shape[0]}steps")
    model.add(tf.keras.layers.Input(shape=input_shape, name="Input_Sequence"))
    model.add(tf.keras.layers.LSTM(units=lstm_units_l1, return_sequences=(lstm_units_l2 > 0), name="LSTM_Layer_1"))
    if lstm_units_l2 > 0: model.add(tf.keras.layers.LSTM(units=lstm_units_l2, return_sequences=False, name="LSTM_Layer_2"))
    if dense_units > 0: model.add(tf.keras.layers.Dense(units=dense_units, activation='relu', name="Dense_Layer"))
    model.add(tf.keras.layers.Dense(units=1, name="Output_Layer"))
    print(f"\nModelo construido:")
    model.summary()
    return model

# ------------------------------------------------------------------------------

def plot_training_history(history, product_id):
    """Crea la figura con las curvas de loss."""
    # (Sin cambios respecto a la versión anterior)
    if history is None or not hasattr(history, 'history') or 'loss' not in history.history or 'val_loss' not in history.history: return None
    fig = plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Pérdida Entrenamiento')
    plt.plot(history.history['val_loss'], label='Pérdida Validación')
    plt.title(f'Historial Entrenamiento - PID: {product_id}')
    plt.xlabel('Época')
    plt.ylabel('Pérdida (MSE)')
    plt.legend()
    plt.grid(True)
    plt.ylim(bottom=0)
    return fig

# ------------------------------------------------------------------------------

def train_product_model(product_id, data_dict, lstm_params, train_params):
    """Entrena un modelo LSTM para un producto específico."""
    # (Sin cambios respecto a la versión anterior)
    if product_id not in data_dict: return None, None
    X_train = data_dict[product_id].get('X_train')
    y_train = data_dict[product_id].get('y_train')
    X_test = data_dict[product_id].get('X_test')
    y_test = data_dict[product_id].get('y_test')
    if X_train is None or y_train is None or X_test is None or y_test is None or X_train.shape[0] == 0 or X_test.shape[0] == 0:
        print(f"Error: Datos train/test vacíos/faltantes para {product_id}.")
        return None, None

    print(f"\n--- Entrenando Modelo para PID: {product_id} ---")
    input_shape = (X_train.shape[1], X_train.shape[2])
    model = build_lstm_model(input_shape, lstm_params['units_l1'], lstm_params['units_l2'], lstm_params['dense_units'])
    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error')
    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=train_params['patience'], restore_best_weights=True, verbose=1)
    history = model.fit(X_train, y_train, epochs=train_params['epochs'], batch_size=train_params['batch_size'], validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)
    final_loss = model.evaluate(X_test, y_test, verbose=0)
    print(f"Entrenamiento completado para {product_id}. Test Loss (MSE): {final_loss:.6f}")
    return model, history

trained_models = {}
training_histories = {}
training_history_plots = {}

# Verificar si hay productos listos para entrenar
if available_products:
    print(f"\n=== Iniciando Bucle de Entrenamiento para {len(available_products)} productos ===")

    # Definir parámetros para pasar a la función de entrenamiento
    lstm_architecture_params = {
        'units_l1': LSTM_UNITS_L1, 'units_l2': LSTM_UNITS_L2, 'dense_units': DENSE_UNITS
    }
    training_run_params = {
        'epochs': EPOCHS, 'batch_size': BATCH_SIZE, 'patience': PATIENCE_EARLY_STOP
    }

    # --- Crear directorio para guardar modelos si no existe ---
    try:
        os.makedirs(SAVE_DIR, exist_ok=True) # exist_ok=True evita error si ya existe
        print(f"Directorio para guardar modelos: '{SAVE_DIR}'")
    except OSError as error:
        print(f"Error al crear directorio '{SAVE_DIR}': {error}. No se guardarán los modelos.")
        can_save_models = False
    else:
        can_save_models = True
    # --------------------------------------------------------

    # Iterar sobre cada producto disponible
    for product in available_products:
        model, history = train_product_model(product,
                                             data_processed,
                                             lstm_architecture_params,
                                             training_run_params)

        # Guardar resultados si el entrenamiento fue exitoso
        if model and history:
            trained_models[product] = model
            training_histories[product] = history
            fig = plot_training_history(history, product)
            if fig: training_history_plots[product] = fig

            # --- Guardar el modelo entrenado ---
            if can_save_models:
                try:
                    # Construir ruta de guardado
                    save_path = os.path.join(SAVE_DIR, f'lstm_model_{product}.keras')
                    # Guardar el modelo (formato recomendado .keras)
                    model.save(save_path)
                    print(f"  >> Modelo para {product} guardado en: {save_path}")
                except Exception as e:
                    print(f"  >> Error al guardar modelo para {product}: {e}")
            # ------------------------------------

    print(f"\n=== Fin del Bucle de Entrenamiento. Se entrenaron {len(trained_models)} modelos. ===")

else:
    print("\nNo hay productos disponibles para entrenar modelos.")

# --- Mostrar Gráficos de Historial ---
if training_history_plots:
    print("\n--- Mostrando Gráficos de Historial de Entrenamiento ---")
    for product_id, fig in training_history_plots.items():
        plt.figure(fig.number) # Activar la figura correcta
        plt.show() # Mostrarla
    # Opcionalmente, una sola llamada a plt.show() al final puede funcionar en algunos entornos
    # plt.show()
else:
    print("No hay gráficos de historial de entrenamiento para mostrar.")

def plot_predictions_vs_actual(product_id, dates, actual_values, predicted_values):
    """Crea la figura comparando valores reales vs predichos en el test set."""
    # (Sin cambios respecto a la versión anterior)
    fig = plt.figure(figsize=(12, 6))
    plt.plot(dates, actual_values, label='Demanda Real (Test Set)', marker='.', linestyle='-', alpha=0.8)
    plt.plot(dates, predicted_values, label='Predicción Modelo (Test Set)', marker='x', linestyle='--', alpha=0.8)
    plt.title(f'Comparación Real vs. Predicción - PID: {product_id}')
    plt.xlabel('Fecha')
    plt.ylabel('Demanda Semanal')
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=30, ha='right')
    plt.tight_layout()
    return fig

evaluation_plots = {}
if trained_models and data_processed and df_weekly is not None:
    print("\n=== Iniciando Evaluación (Predicción vs Real en Test Set) ===")
    for product in trained_models.keys():
        print(f"\nEvaluando PID: {product}")
        if product not in data_processed: continue
        product_data = data_processed[product]
        X_test = product_data.get('X_test')
        y_test_scaled = product_data.get('y_test')
        scaler = product_data.get('scaler')
        model = trained_models[product]
        if X_test is None or y_test_scaled is None or scaler is None or X_test.shape[0] == 0: continue

        print(f"  Generando predicciones test set...")
        predictions_scaled = model.predict(X_test)
        if y_test_scaled.ndim == 1: y_test_scaled = y_test_scaled.reshape(-1, 1)
        if predictions_scaled.ndim == 1: predictions_scaled = predictions_scaled.reshape(-1, 1)
        try:
            predictions_actual = scaler.inverse_transform(predictions_scaled)
            y_test_actual = scaler.inverse_transform(y_test_scaled)
        except Exception as e: print(f"  Error al revertir escala: {e}"); continue

        try:
            temp_product_data = df_weekly[[product]].values.astype(np.float32)
            temp_scaler = MinMaxScaler(feature_range=(0, 1))
            temp_scaled_data = temp_scaler.fit_transform(temp_product_data)
            X_orig_seq, y_orig_seq = create_sequences(temp_scaled_data, SEQUENCE_LENGTH)
            if X_orig_seq.shape[0] < 2: raise ValueError("Insuficientes secuencias.")
            split_index = int(X_orig_seq.shape[0] * (1 - TEST_SPLIT_RATIO))
            split_index = max(1, min(split_index, X_orig_seq.shape[0] - 1))
            start_index = split_index + SEQUENCE_LENGTH
            end_index = start_index + len(y_test_actual)
            if start_index >= len(df_weekly) or end_index > len(df_weekly):
                print(f"  Advertencia: Índices fecha ({start_index}:{end_index}) fuera de rango ({len(df_weekly)}). Ajustando...")
                end_index = min(end_index, len(df_weekly))
                num_points = end_index - start_index
                if num_points <= 0: raise IndexError("Índices inválidos.")
                y_test_actual = y_test_actual[:num_points]
                predictions_actual = predictions_actual[:num_points]
            test_dates = df_weekly.index[start_index : end_index]
            if len(test_dates) != len(y_test_actual): raise ValueError("Discrepancia longitud fechas vs y_test.")
            print(f"  Fechas Test set: {test_dates.min().date()} a {test_dates.max().date()}")
            fig = plot_predictions_vs_actual(product, test_dates, y_test_actual, predictions_actual)
            if fig: evaluation_plots[product] = fig
        except Exception as e: print(f"  Error al obtener fechas/graficar: {e}"); continue
    print("\n=== Fin Evaluación ===")
else: print("\nNo se puede evaluar: faltan modelos/datos.")

if evaluation_plots:
    print("\n--- Mostrando Gráficos de Evaluación ---")
    for product_id, fig in evaluation_plots.items():
         plt.figure(fig.number)
         plt.show()
    # plt.show() # Alternativa: llamada única al final
else: print("No se generaron gráficos de evaluación.")

# --- Función para Generar Pronósticos Futuros ---
def generate_forecast(product_id, model, last_sequence, scaler, n_future_steps, seq_len):
    """Genera pronósticos para n_future_steps semanas futuras."""
    if model is None or last_sequence is None or scaler is None:
        print(f"Error: Faltan datos (modelo/secuencia/scaler) para pronosticar {product_id}.")
        return None

    print(f"\n--- Generando Pronóstico de {n_future_steps} semanas futuras para PID: {product_id} ---")
    forecast_scaled = [] # Lista para guardar predicciones escaladas
    current_sequence = last_sequence.copy() # Trabajar con una copia

    # Bucle para generar cada paso futuro
    for _ in range(n_future_steps):
        # Predecir el siguiente paso (escalado)
        # El modelo espera [batch=1, timesteps=seq_len, features=1]
        next_pred_scaled = model.predict(current_sequence, verbose=0)[0, 0]
        forecast_scaled.append(next_pred_scaled)

        # Actualizar la secuencia de entrada para la siguiente predicción:
        # quitar el valor más antiguo y añadir la nueva predicción (escalada) al final
        new_sequence_entry_scaled = np.array([[[next_pred_scaled]]]).astype(np.float32) # Forma [1, 1, 1]
        # Concatenar: tomar desde el segundo paso hasta el final, y añadir el nuevo
        current_sequence = np.append(current_sequence[:, 1:, :], new_sequence_entry_scaled, axis=1)

    # Revertir la escala de todas las predicciones futuras a la vez
    try:
        forecast_actual = scaler.inverse_transform(np.array(forecast_scaled).reshape(-1, 1))
    except Exception as e:
        print(f"  Error al revertir la escala del pronóstico futuro para {product_id}: {e}")
        return None

    return forecast_actual.flatten() # Devolver como array 1D

# --- Lógica para Generar y Mostrar Pronósticos Futuros ---
forecasts = {} # Diccionario para guardar los pronósticos futuros

# Verificar si hay modelos y datos para pronosticar
if trained_models and data_processed and df_weekly is not None:
    print(f"\n=== Iniciando Pronóstico Futuro ({N_FUTURE_WEEKS} semanas) ===")

    # Decidir para qué productos pronosticar (ejemplo: todos los disponibles)
    products_to_forecast = list(trained_models.keys())
    print(f"Se generarán pronósticos para: {products_to_forecast}")

    for product in products_to_forecast:
        if product not in data_processed:
            print(f"  Advertencia: Datos procesados no encontrados para {product}. Saltando pronóstico futuro.")
            continue

        # Obtener los componentes necesarios
        model = trained_models[product]
        last_sequence = data_processed[product].get('last_sequence') # Última secuencia conocida (escalada)
        scaler = data_processed[product].get('scaler')

        # Validar componentes
        if model is None or last_sequence is None or scaler is None or \
           last_sequence.shape != (1, SEQUENCE_LENGTH, 1): # Verificar forma de la secuencia
            print(f"  Advertencia: Modelo, última secuencia o scaler inválido/faltante para {product}. Saltando pronóstico futuro.")
            continue

        # Generar el pronóstico
        forecast_values = generate_forecast(product, model, last_sequence, scaler, N_FUTURE_WEEKS, SEQUENCE_LENGTH)

        if forecast_values is not None:
            forecasts[product] = forecast_values

    print("\n=== Fin del Pronóstico Futuro ===")

else:
    print("\nNo se puede realizar pronóstico futuro: faltan modelos, datos procesados o df_weekly.")


# --- Mostrar y Graficar Pronósticos Futuros ---
if forecasts:
    print("\n--- Resultados del Pronóstico Futuro ---")

    # Crear DataFrame para los pronósticos
    if not df_weekly.empty:
        last_date = df_weekly.index.max()
        # Generar fechas futuras empezando la semana después de la última conocida
        forecast_dates = pd.date_range(start=last_date + pd.Timedelta(weeks=1), periods=N_FUTURE_WEEKS, freq='W-MON')
        df_forecast = pd.DataFrame(index=forecast_dates)
        print(f"Pronósticos desde {forecast_dates.min().date()} hasta {forecast_dates.max().date()}")

        for product, forecast_values in forecasts.items():
            print(f"\nPronóstico para PID {product}:")
            if len(forecast_values) == len(forecast_dates):
                df_forecast[f'{product}_Forecast'] = forecast_values
                # Imprimir primeros valores
                for i in range(min(5, len(forecast_dates))):
                    print(f"  Semana {forecast_dates[i].strftime('%Y-%m-%d')}: {forecast_values[i]:.2f}")
                if len(forecast_dates) > 5: print("  ...")
            else:
                 print(f"  Error: Longitud del pronóstico ({len(forecast_values)}) != número de semanas ({len(forecast_dates)}).")

        print("\nDataFrame de Pronósticos Futuros:")
        print(df_forecast)

        # --- Graficar Pronósticos Futuros (Opcional) ---
        print("\nGenerando gráficos de pronóstico futuro...")
        n_plots = len(forecasts)
        plt.figure(figsize=(15, 5 * n_plots))
        plot_index = 1
        for product in forecasts.keys():
            if product in df_weekly.columns: # Verificar si hay datos históricos
                plt.subplot(n_plots, 1, plot_index)
                # Graficar últimos datos históricos (ej: último año)
                plt.plot(df_weekly.index[-52:], df_weekly[product][-52:], label=f'Histórico {product} (Último año)')
                # Graficar pronóstico futuro
                if f'{product}_Forecast' in df_forecast.columns:
                     plt.plot(df_forecast.index, df_forecast[f'{product}_Forecast'], label=f'Pronóstico Futuro {product}', linestyle='--')
                plt.title(f'Demanda Semanal y Pronóstico Futuro - PID {product}')
                plt.ylabel(DEMAND_COLUMN)
                plt.legend()
                plt.grid(True)
                plot_index += 1
        plt.xlabel('Fecha')
        plt.tight_layout()
        plt.show() # Mostrar gráfico de pronósticos

    else:
        print("No se pueden generar fechas/DataFrame de pronóstico porque df_weekly está vacío.")

else:
    print("No se generaron pronósticos futuros.")


print("\n--- Proceso Completo Finalizado ---")